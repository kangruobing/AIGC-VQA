{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b266a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import BLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b488cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BLIP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb44537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual_encoder.cls_token: torch.Size([1, 1, 1024]), requires_grad=True\n",
      "visual_encoder.pos_embed: torch.Size([1, 197, 1024]), requires_grad=True\n",
      "visual_encoder.patch_embed.proj.weight: torch.Size([1024, 3, 16, 16]), requires_grad=True\n",
      "visual_encoder.patch_embed.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.0.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.0.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.0.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.0.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.0.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.0.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.0.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.0.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.0.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.0.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.0.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.0.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.1.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.1.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.1.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.1.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.1.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.1.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.1.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.1.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.1.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.1.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.1.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.1.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.2.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.2.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.2.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.2.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.2.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.2.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.2.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.2.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.2.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.2.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.2.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.2.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.3.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.3.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.3.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.3.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.3.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.3.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.3.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.3.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.3.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.3.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.3.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.3.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.4.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.4.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.4.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.4.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.4.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.4.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.4.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.4.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.4.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.4.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.4.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.4.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.5.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.5.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.5.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.5.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.5.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.5.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.5.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.5.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.5.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.5.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.5.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.5.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.6.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.6.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.6.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.6.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.6.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.6.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.6.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.6.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.6.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.6.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.6.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.6.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.7.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.7.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.7.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.7.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.7.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.7.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.7.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.7.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.7.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.7.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.7.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.7.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.8.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.8.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.8.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.8.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.8.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.8.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.8.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.8.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.8.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.8.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.8.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.8.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.9.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.9.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.9.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.9.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.9.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.9.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.9.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.9.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.9.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.9.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.9.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.9.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.10.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.10.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.10.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.10.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.10.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.10.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.10.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.10.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.10.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.10.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.10.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.10.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.11.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.11.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.11.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.11.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.11.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.11.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.11.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.11.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.11.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.11.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.11.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.11.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.12.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.12.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.12.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.12.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.12.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.12.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.12.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.12.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.12.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.12.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.12.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.12.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.13.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.13.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.13.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.13.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.13.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.13.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.13.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.13.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.13.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.13.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.13.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.13.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.14.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.14.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.14.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.14.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.14.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.14.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.14.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.14.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.14.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.14.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.14.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.14.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.15.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.15.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.15.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.15.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.15.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.15.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.15.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.15.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.15.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.15.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.15.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.15.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.16.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.16.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.16.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.16.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.16.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.16.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.16.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.16.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.16.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.16.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.16.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.16.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.17.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.17.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.17.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.17.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.17.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.17.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.17.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.17.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.17.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.17.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.17.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.17.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.18.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.18.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.18.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.18.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.18.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.18.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.18.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.18.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.18.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.18.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.18.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.18.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.19.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.19.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.19.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.19.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.19.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.19.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.19.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.19.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.19.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.19.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.19.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.19.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.20.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.20.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.20.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.20.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.20.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.20.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.20.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.20.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.20.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.20.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.20.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.20.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.21.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.21.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.21.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.21.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.21.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.21.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.21.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.21.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.21.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.21.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.21.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.21.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.22.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.22.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.22.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.22.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.22.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.22.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.22.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.22.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.22.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.22.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.22.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.22.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.23.norm1.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.23.norm1.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.23.attn.qkv.weight: torch.Size([3072, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.23.attn.qkv.bias: torch.Size([3072]), requires_grad=True\n",
      "visual_encoder.blocks.23.attn.proj.weight: torch.Size([1024, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.23.attn.proj.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.23.norm2.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.23.norm2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.blocks.23.mlp.fc1.weight: torch.Size([4096, 1024]), requires_grad=True\n",
      "visual_encoder.blocks.23.mlp.fc1.bias: torch.Size([4096]), requires_grad=True\n",
      "visual_encoder.blocks.23.mlp.fc2.weight: torch.Size([1024, 4096]), requires_grad=True\n",
      "visual_encoder.blocks.23.mlp.fc2.bias: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.norm.weight: torch.Size([1024]), requires_grad=True\n",
      "visual_encoder.norm.bias: torch.Size([1024]), requires_grad=True\n",
      "text_encoder.embeddings.word_embeddings.weight: torch.Size([30524, 768]), requires_grad=True\n",
      "text_encoder.embeddings.position_embeddings.weight: torch.Size([512, 768]), requires_grad=True\n",
      "text_encoder.embeddings.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.embeddings.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.attention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.attention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.attention.self.key.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.attention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.attention.self.value.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.attention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.attention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.attention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.attention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.attention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.crossattention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.crossattention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.crossattention.self.key.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.crossattention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.crossattention.self.value.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.crossattention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.crossattention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.crossattention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.crossattention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.crossattention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.intermediate.dense.weight: torch.Size([3072, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.intermediate.dense.bias: torch.Size([3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.output.dense.weight: torch.Size([768, 3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.0.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.attention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.attention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.attention.self.key.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.attention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.attention.self.value.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.attention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.attention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.attention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.attention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.attention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.crossattention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.crossattention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.crossattention.self.key.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.crossattention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.crossattention.self.value.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.crossattention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.crossattention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.crossattention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.crossattention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.crossattention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.intermediate.dense.weight: torch.Size([3072, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.intermediate.dense.bias: torch.Size([3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.output.dense.weight: torch.Size([768, 3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.1.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.attention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.attention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.attention.self.key.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.attention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.attention.self.value.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.attention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.attention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.attention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.attention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.attention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.crossattention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.crossattention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.crossattention.self.key.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.crossattention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.crossattention.self.value.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.crossattention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.crossattention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.crossattention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.crossattention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.crossattention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.intermediate.dense.weight: torch.Size([3072, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.intermediate.dense.bias: torch.Size([3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.output.dense.weight: torch.Size([768, 3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.2.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.attention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.attention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.attention.self.key.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.attention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.attention.self.value.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.attention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.attention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.attention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.attention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.attention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.crossattention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.crossattention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.crossattention.self.key.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.crossattention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.crossattention.self.value.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.crossattention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.crossattention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.crossattention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.crossattention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.crossattention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.intermediate.dense.weight: torch.Size([3072, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.intermediate.dense.bias: torch.Size([3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.output.dense.weight: torch.Size([768, 3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.3.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.attention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.attention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.attention.self.key.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.attention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.attention.self.value.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.attention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.attention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.attention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.attention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.attention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.crossattention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.crossattention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.crossattention.self.key.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.crossattention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.crossattention.self.value.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.crossattention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.crossattention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.crossattention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.crossattention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.crossattention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.intermediate.dense.weight: torch.Size([3072, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.intermediate.dense.bias: torch.Size([3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.output.dense.weight: torch.Size([768, 3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.4.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.attention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.attention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.attention.self.key.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.attention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.attention.self.value.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.attention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.attention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.attention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.attention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.attention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.crossattention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.crossattention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.crossattention.self.key.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.crossattention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.crossattention.self.value.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.crossattention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.crossattention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.crossattention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.crossattention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.crossattention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.intermediate.dense.weight: torch.Size([3072, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.intermediate.dense.bias: torch.Size([3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.output.dense.weight: torch.Size([768, 3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.5.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.attention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.attention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.attention.self.key.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.attention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.attention.self.value.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.attention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.attention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.attention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.attention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.attention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.crossattention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.crossattention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.crossattention.self.key.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.crossattention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.crossattention.self.value.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.crossattention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.crossattention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.crossattention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.crossattention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.crossattention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.intermediate.dense.weight: torch.Size([3072, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.intermediate.dense.bias: torch.Size([3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.output.dense.weight: torch.Size([768, 3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.6.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.attention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.attention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.attention.self.key.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.attention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.attention.self.value.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.attention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.attention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.attention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.attention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.attention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.crossattention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.crossattention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.crossattention.self.key.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.crossattention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.crossattention.self.value.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.crossattention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.crossattention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.crossattention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.crossattention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.crossattention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.intermediate.dense.weight: torch.Size([3072, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.intermediate.dense.bias: torch.Size([3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.output.dense.weight: torch.Size([768, 3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.7.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.attention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.attention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.attention.self.key.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.attention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.attention.self.value.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.attention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.attention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.attention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.attention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.attention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.crossattention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.crossattention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.crossattention.self.key.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.crossattention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.crossattention.self.value.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.crossattention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.crossattention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.crossattention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.crossattention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.crossattention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.intermediate.dense.weight: torch.Size([3072, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.intermediate.dense.bias: torch.Size([3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.output.dense.weight: torch.Size([768, 3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.8.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.attention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.attention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.attention.self.key.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.attention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.attention.self.value.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.attention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.attention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.attention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.attention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.attention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.crossattention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.crossattention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.crossattention.self.key.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.crossattention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.crossattention.self.value.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.crossattention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.crossattention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.crossattention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.intermediate.dense.weight: torch.Size([3072, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.intermediate.dense.bias: torch.Size([3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.output.dense.weight: torch.Size([768, 3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.9.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.attention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.attention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.attention.self.key.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.attention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.attention.self.value.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.attention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.attention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.attention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.attention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.attention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.crossattention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.crossattention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.crossattention.self.key.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.crossattention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.crossattention.self.value.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.crossattention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.crossattention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.crossattention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.intermediate.dense.weight: torch.Size([3072, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.intermediate.dense.bias: torch.Size([3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.output.dense.weight: torch.Size([768, 3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.10.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.attention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.attention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.attention.self.key.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.attention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.attention.self.value.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.attention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.attention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.attention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.attention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.attention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.crossattention.self.query.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.crossattention.self.query.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.crossattention.self.key.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.crossattention.self.key.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.crossattention.self.value.weight: torch.Size([768, 1024]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.crossattention.self.value.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.crossattention.output.dense.weight: torch.Size([768, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.crossattention.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.intermediate.dense.weight: torch.Size([3072, 768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.intermediate.dense.bias: torch.Size([3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.output.dense.weight: torch.Size([768, 3072]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.output.dense.bias: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.output.LayerNorm.weight: torch.Size([768]), requires_grad=True\n",
      "text_encoder.encoder.layer.11.output.LayerNorm.bias: torch.Size([768]), requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}, requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5193e22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blip.visual_encoder.cls_token\n",
      "blip.visual_encoder.pos_embed\n",
      "blip.visual_encoder.patch_embed.proj.weight\n",
      "blip.visual_encoder.patch_embed.proj.bias\n",
      "blip.visual_encoder.blocks.0.norm1.weight\n",
      "blip.visual_encoder.blocks.0.norm1.bias\n",
      "blip.visual_encoder.blocks.0.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.0.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.0.attn.proj.weight\n",
      "blip.visual_encoder.blocks.0.attn.proj.bias\n",
      "blip.visual_encoder.blocks.0.norm2.weight\n",
      "blip.visual_encoder.blocks.0.norm2.bias\n",
      "blip.visual_encoder.blocks.0.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.0.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.0.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.0.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.1.norm1.weight\n",
      "blip.visual_encoder.blocks.1.norm1.bias\n",
      "blip.visual_encoder.blocks.1.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.1.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.1.attn.proj.weight\n",
      "blip.visual_encoder.blocks.1.attn.proj.bias\n",
      "blip.visual_encoder.blocks.1.norm2.weight\n",
      "blip.visual_encoder.blocks.1.norm2.bias\n",
      "blip.visual_encoder.blocks.1.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.1.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.1.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.1.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.2.norm1.weight\n",
      "blip.visual_encoder.blocks.2.norm1.bias\n",
      "blip.visual_encoder.blocks.2.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.2.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.2.attn.proj.weight\n",
      "blip.visual_encoder.blocks.2.attn.proj.bias\n",
      "blip.visual_encoder.blocks.2.norm2.weight\n",
      "blip.visual_encoder.blocks.2.norm2.bias\n",
      "blip.visual_encoder.blocks.2.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.2.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.2.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.2.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.3.norm1.weight\n",
      "blip.visual_encoder.blocks.3.norm1.bias\n",
      "blip.visual_encoder.blocks.3.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.3.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.3.attn.proj.weight\n",
      "blip.visual_encoder.blocks.3.attn.proj.bias\n",
      "blip.visual_encoder.blocks.3.norm2.weight\n",
      "blip.visual_encoder.blocks.3.norm2.bias\n",
      "blip.visual_encoder.blocks.3.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.3.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.3.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.3.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.4.norm1.weight\n",
      "blip.visual_encoder.blocks.4.norm1.bias\n",
      "blip.visual_encoder.blocks.4.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.4.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.4.attn.proj.weight\n",
      "blip.visual_encoder.blocks.4.attn.proj.bias\n",
      "blip.visual_encoder.blocks.4.norm2.weight\n",
      "blip.visual_encoder.blocks.4.norm2.bias\n",
      "blip.visual_encoder.blocks.4.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.4.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.4.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.4.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.5.norm1.weight\n",
      "blip.visual_encoder.blocks.5.norm1.bias\n",
      "blip.visual_encoder.blocks.5.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.5.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.5.attn.proj.weight\n",
      "blip.visual_encoder.blocks.5.attn.proj.bias\n",
      "blip.visual_encoder.blocks.5.norm2.weight\n",
      "blip.visual_encoder.blocks.5.norm2.bias\n",
      "blip.visual_encoder.blocks.5.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.5.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.5.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.5.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.6.norm1.weight\n",
      "blip.visual_encoder.blocks.6.norm1.bias\n",
      "blip.visual_encoder.blocks.6.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.6.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.6.attn.proj.weight\n",
      "blip.visual_encoder.blocks.6.attn.proj.bias\n",
      "blip.visual_encoder.blocks.6.norm2.weight\n",
      "blip.visual_encoder.blocks.6.norm2.bias\n",
      "blip.visual_encoder.blocks.6.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.6.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.6.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.6.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.7.norm1.weight\n",
      "blip.visual_encoder.blocks.7.norm1.bias\n",
      "blip.visual_encoder.blocks.7.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.7.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.7.attn.proj.weight\n",
      "blip.visual_encoder.blocks.7.attn.proj.bias\n",
      "blip.visual_encoder.blocks.7.norm2.weight\n",
      "blip.visual_encoder.blocks.7.norm2.bias\n",
      "blip.visual_encoder.blocks.7.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.7.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.7.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.7.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.8.norm1.weight\n",
      "blip.visual_encoder.blocks.8.norm1.bias\n",
      "blip.visual_encoder.blocks.8.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.8.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.8.attn.proj.weight\n",
      "blip.visual_encoder.blocks.8.attn.proj.bias\n",
      "blip.visual_encoder.blocks.8.norm2.weight\n",
      "blip.visual_encoder.blocks.8.norm2.bias\n",
      "blip.visual_encoder.blocks.8.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.8.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.8.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.8.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.9.norm1.weight\n",
      "blip.visual_encoder.blocks.9.norm1.bias\n",
      "blip.visual_encoder.blocks.9.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.9.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.9.attn.proj.weight\n",
      "blip.visual_encoder.blocks.9.attn.proj.bias\n",
      "blip.visual_encoder.blocks.9.norm2.weight\n",
      "blip.visual_encoder.blocks.9.norm2.bias\n",
      "blip.visual_encoder.blocks.9.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.9.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.9.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.9.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.10.norm1.weight\n",
      "blip.visual_encoder.blocks.10.norm1.bias\n",
      "blip.visual_encoder.blocks.10.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.10.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.10.attn.proj.weight\n",
      "blip.visual_encoder.blocks.10.attn.proj.bias\n",
      "blip.visual_encoder.blocks.10.norm2.weight\n",
      "blip.visual_encoder.blocks.10.norm2.bias\n",
      "blip.visual_encoder.blocks.10.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.10.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.10.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.10.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.11.norm1.weight\n",
      "blip.visual_encoder.blocks.11.norm1.bias\n",
      "blip.visual_encoder.blocks.11.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.11.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.11.attn.proj.weight\n",
      "blip.visual_encoder.blocks.11.attn.proj.bias\n",
      "blip.visual_encoder.blocks.11.norm2.weight\n",
      "blip.visual_encoder.blocks.11.norm2.bias\n",
      "blip.visual_encoder.blocks.11.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.11.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.11.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.11.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.12.norm1.weight\n",
      "blip.visual_encoder.blocks.12.norm1.bias\n",
      "blip.visual_encoder.blocks.12.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.12.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.12.attn.proj.weight\n",
      "blip.visual_encoder.blocks.12.attn.proj.bias\n",
      "blip.visual_encoder.blocks.12.norm2.weight\n",
      "blip.visual_encoder.blocks.12.norm2.bias\n",
      "blip.visual_encoder.blocks.12.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.12.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.12.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.12.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.13.norm1.weight\n",
      "blip.visual_encoder.blocks.13.norm1.bias\n",
      "blip.visual_encoder.blocks.13.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.13.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.13.attn.proj.weight\n",
      "blip.visual_encoder.blocks.13.attn.proj.bias\n",
      "blip.visual_encoder.blocks.13.norm2.weight\n",
      "blip.visual_encoder.blocks.13.norm2.bias\n",
      "blip.visual_encoder.blocks.13.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.13.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.13.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.13.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.14.norm1.weight\n",
      "blip.visual_encoder.blocks.14.norm1.bias\n",
      "blip.visual_encoder.blocks.14.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.14.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.14.attn.proj.weight\n",
      "blip.visual_encoder.blocks.14.attn.proj.bias\n",
      "blip.visual_encoder.blocks.14.norm2.weight\n",
      "blip.visual_encoder.blocks.14.norm2.bias\n",
      "blip.visual_encoder.blocks.14.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.14.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.14.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.14.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.15.norm1.weight\n",
      "blip.visual_encoder.blocks.15.norm1.bias\n",
      "blip.visual_encoder.blocks.15.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.15.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.15.attn.proj.weight\n",
      "blip.visual_encoder.blocks.15.attn.proj.bias\n",
      "blip.visual_encoder.blocks.15.norm2.weight\n",
      "blip.visual_encoder.blocks.15.norm2.bias\n",
      "blip.visual_encoder.blocks.15.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.15.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.15.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.15.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.16.norm1.weight\n",
      "blip.visual_encoder.blocks.16.norm1.bias\n",
      "blip.visual_encoder.blocks.16.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.16.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.16.attn.proj.weight\n",
      "blip.visual_encoder.blocks.16.attn.proj.bias\n",
      "blip.visual_encoder.blocks.16.norm2.weight\n",
      "blip.visual_encoder.blocks.16.norm2.bias\n",
      "blip.visual_encoder.blocks.16.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.16.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.16.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.16.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.17.norm1.weight\n",
      "blip.visual_encoder.blocks.17.norm1.bias\n",
      "blip.visual_encoder.blocks.17.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.17.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.17.attn.proj.weight\n",
      "blip.visual_encoder.blocks.17.attn.proj.bias\n",
      "blip.visual_encoder.blocks.17.norm2.weight\n",
      "blip.visual_encoder.blocks.17.norm2.bias\n",
      "blip.visual_encoder.blocks.17.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.17.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.17.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.17.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.18.norm1.weight\n",
      "blip.visual_encoder.blocks.18.norm1.bias\n",
      "blip.visual_encoder.blocks.18.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.18.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.18.attn.proj.weight\n",
      "blip.visual_encoder.blocks.18.attn.proj.bias\n",
      "blip.visual_encoder.blocks.18.norm2.weight\n",
      "blip.visual_encoder.blocks.18.norm2.bias\n",
      "blip.visual_encoder.blocks.18.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.18.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.18.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.18.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.19.norm1.weight\n",
      "blip.visual_encoder.blocks.19.norm1.bias\n",
      "blip.visual_encoder.blocks.19.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.19.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.19.attn.proj.weight\n",
      "blip.visual_encoder.blocks.19.attn.proj.bias\n",
      "blip.visual_encoder.blocks.19.norm2.weight\n",
      "blip.visual_encoder.blocks.19.norm2.bias\n",
      "blip.visual_encoder.blocks.19.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.19.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.19.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.19.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.20.norm1.weight\n",
      "blip.visual_encoder.blocks.20.norm1.bias\n",
      "blip.visual_encoder.blocks.20.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.20.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.20.attn.proj.weight\n",
      "blip.visual_encoder.blocks.20.attn.proj.bias\n",
      "blip.visual_encoder.blocks.20.norm2.weight\n",
      "blip.visual_encoder.blocks.20.norm2.bias\n",
      "blip.visual_encoder.blocks.20.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.20.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.20.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.20.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.21.norm1.weight\n",
      "blip.visual_encoder.blocks.21.norm1.bias\n",
      "blip.visual_encoder.blocks.21.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.21.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.21.attn.proj.weight\n",
      "blip.visual_encoder.blocks.21.attn.proj.bias\n",
      "blip.visual_encoder.blocks.21.norm2.weight\n",
      "blip.visual_encoder.blocks.21.norm2.bias\n",
      "blip.visual_encoder.blocks.21.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.21.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.21.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.21.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.22.norm1.weight\n",
      "blip.visual_encoder.blocks.22.norm1.bias\n",
      "blip.visual_encoder.blocks.22.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.22.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.22.attn.proj.weight\n",
      "blip.visual_encoder.blocks.22.attn.proj.bias\n",
      "blip.visual_encoder.blocks.22.norm2.weight\n",
      "blip.visual_encoder.blocks.22.norm2.bias\n",
      "blip.visual_encoder.blocks.22.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.22.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.22.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.22.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.23.norm1.weight\n",
      "blip.visual_encoder.blocks.23.norm1.bias\n",
      "blip.visual_encoder.blocks.23.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.23.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.23.attn.proj.weight\n",
      "blip.visual_encoder.blocks.23.attn.proj.bias\n",
      "blip.visual_encoder.blocks.23.norm2.weight\n",
      "blip.visual_encoder.blocks.23.norm2.bias\n",
      "blip.visual_encoder.blocks.23.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.23.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.23.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.23.mlp.fc2.bias\n",
      "blip.visual_encoder.norm.weight\n",
      "blip.visual_encoder.norm.bias\n",
      "blip.text_encoder.embeddings.position_ids\n",
      "blip.text_encoder.embeddings.word_embeddings.weight\n",
      "blip.text_encoder.embeddings.position_embeddings.weight\n",
      "blip.text_encoder.embeddings.LayerNorm.weight\n",
      "blip.text_encoder.embeddings.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.0.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.0.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.0.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.0.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.0.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.0.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.0.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.0.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.0.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.0.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.0.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.0.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.0.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.0.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.0.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.0.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.0.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.0.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.0.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.0.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.0.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.0.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.0.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.0.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.1.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.1.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.1.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.1.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.1.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.1.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.1.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.1.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.1.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.1.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.1.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.1.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.1.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.1.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.1.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.1.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.1.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.1.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.1.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.1.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.1.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.1.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.1.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.1.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.2.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.2.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.2.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.2.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.2.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.2.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.2.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.2.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.2.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.2.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.2.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.2.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.2.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.2.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.2.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.2.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.2.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.2.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.2.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.2.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.2.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.2.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.2.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.2.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.3.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.3.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.3.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.3.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.3.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.3.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.3.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.3.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.3.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.3.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.3.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.3.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.3.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.3.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.3.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.3.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.3.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.3.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.3.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.3.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.3.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.3.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.3.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.3.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.4.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.4.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.4.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.4.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.4.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.4.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.4.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.4.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.4.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.4.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.4.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.4.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.4.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.4.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.4.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.4.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.4.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.4.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.4.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.4.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.4.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.4.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.4.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.4.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.5.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.5.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.5.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.5.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.5.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.5.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.5.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.5.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.5.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.5.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.5.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.5.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.5.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.5.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.5.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.5.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.5.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.5.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.5.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.5.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.5.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.5.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.5.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.5.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.6.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.6.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.6.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.6.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.6.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.6.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.6.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.6.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.6.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.6.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.6.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.6.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.6.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.6.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.6.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.6.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.6.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.6.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.6.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.6.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.6.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.6.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.6.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.6.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.7.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.7.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.7.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.7.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.7.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.7.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.7.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.7.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.7.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.7.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.7.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.7.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.7.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.7.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.7.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.7.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.7.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.7.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.7.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.7.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.7.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.7.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.7.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.7.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.8.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.8.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.8.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.8.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.8.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.8.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.8.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.8.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.8.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.8.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.8.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.8.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.8.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.8.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.8.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.8.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.8.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.8.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.8.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.8.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.8.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.8.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.8.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.8.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.9.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.9.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.9.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.9.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.9.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.9.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.9.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.9.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.9.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.9.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.9.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.9.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.9.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.9.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.9.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.9.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.9.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.9.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.9.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.9.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.9.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.9.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.10.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.10.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.10.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.10.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.10.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.10.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.10.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.10.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.10.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.10.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.10.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.10.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.10.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.10.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.10.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.10.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.10.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.10.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.10.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.10.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.10.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.10.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.11.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.11.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.11.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.11.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.11.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.11.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.11.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.11.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.11.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.11.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.11.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.11.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.11.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.11.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.11.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.11.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.11.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.11.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.11.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.11.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.11.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.11.output.LayerNorm.bias\n",
      "blip.vision_proj.weight\n",
      "blip.vision_proj.bias\n",
      "blip.text_proj.weight\n",
      "blip.text_proj.bias\n",
      "mlp.layers.0.weight\n",
      "mlp.layers.0.bias\n",
      "mlp.layers.2.weight\n",
      "mlp.layers.2.bias\n",
      "mlp.layers.4.weight\n",
      "mlp.layers.4.bias\n",
      "mlp.layers.6.weight\n",
      "mlp.layers.6.bias\n",
      "mlp.layers.7.weight\n",
      "mlp.layers.7.bias\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "state_dict = torch.load(\"/root/autodl-tmp/VQualA/alignment_module/imagereward.pth\")\n",
    "\n",
    "for key, value in state_dict.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9bddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blip.visual_encoder.cls_token\n",
      "blip.visual_encoder.pos_embed\n",
      "blip.visual_encoder.patch_embed.proj.weight\n",
      "blip.visual_encoder.patch_embed.proj.bias\n",
      "blip.visual_encoder.blocks.0.norm1.weight\n",
      "blip.visual_encoder.blocks.0.norm1.bias\n",
      "blip.visual_encoder.blocks.0.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.0.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.0.attn.proj.weight\n",
      "blip.visual_encoder.blocks.0.attn.proj.bias\n",
      "blip.visual_encoder.blocks.0.norm2.weight\n",
      "blip.visual_encoder.blocks.0.norm2.bias\n",
      "blip.visual_encoder.blocks.0.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.0.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.0.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.0.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.1.norm1.weight\n",
      "blip.visual_encoder.blocks.1.norm1.bias\n",
      "blip.visual_encoder.blocks.1.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.1.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.1.attn.proj.weight\n",
      "blip.visual_encoder.blocks.1.attn.proj.bias\n",
      "blip.visual_encoder.blocks.1.norm2.weight\n",
      "blip.visual_encoder.blocks.1.norm2.bias\n",
      "blip.visual_encoder.blocks.1.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.1.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.1.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.1.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.2.norm1.weight\n",
      "blip.visual_encoder.blocks.2.norm1.bias\n",
      "blip.visual_encoder.blocks.2.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.2.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.2.attn.proj.weight\n",
      "blip.visual_encoder.blocks.2.attn.proj.bias\n",
      "blip.visual_encoder.blocks.2.norm2.weight\n",
      "blip.visual_encoder.blocks.2.norm2.bias\n",
      "blip.visual_encoder.blocks.2.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.2.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.2.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.2.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.3.norm1.weight\n",
      "blip.visual_encoder.blocks.3.norm1.bias\n",
      "blip.visual_encoder.blocks.3.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.3.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.3.attn.proj.weight\n",
      "blip.visual_encoder.blocks.3.attn.proj.bias\n",
      "blip.visual_encoder.blocks.3.norm2.weight\n",
      "blip.visual_encoder.blocks.3.norm2.bias\n",
      "blip.visual_encoder.blocks.3.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.3.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.3.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.3.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.4.norm1.weight\n",
      "blip.visual_encoder.blocks.4.norm1.bias\n",
      "blip.visual_encoder.blocks.4.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.4.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.4.attn.proj.weight\n",
      "blip.visual_encoder.blocks.4.attn.proj.bias\n",
      "blip.visual_encoder.blocks.4.norm2.weight\n",
      "blip.visual_encoder.blocks.4.norm2.bias\n",
      "blip.visual_encoder.blocks.4.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.4.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.4.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.4.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.5.norm1.weight\n",
      "blip.visual_encoder.blocks.5.norm1.bias\n",
      "blip.visual_encoder.blocks.5.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.5.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.5.attn.proj.weight\n",
      "blip.visual_encoder.blocks.5.attn.proj.bias\n",
      "blip.visual_encoder.blocks.5.norm2.weight\n",
      "blip.visual_encoder.blocks.5.norm2.bias\n",
      "blip.visual_encoder.blocks.5.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.5.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.5.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.5.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.6.norm1.weight\n",
      "blip.visual_encoder.blocks.6.norm1.bias\n",
      "blip.visual_encoder.blocks.6.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.6.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.6.attn.proj.weight\n",
      "blip.visual_encoder.blocks.6.attn.proj.bias\n",
      "blip.visual_encoder.blocks.6.norm2.weight\n",
      "blip.visual_encoder.blocks.6.norm2.bias\n",
      "blip.visual_encoder.blocks.6.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.6.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.6.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.6.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.7.norm1.weight\n",
      "blip.visual_encoder.blocks.7.norm1.bias\n",
      "blip.visual_encoder.blocks.7.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.7.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.7.attn.proj.weight\n",
      "blip.visual_encoder.blocks.7.attn.proj.bias\n",
      "blip.visual_encoder.blocks.7.norm2.weight\n",
      "blip.visual_encoder.blocks.7.norm2.bias\n",
      "blip.visual_encoder.blocks.7.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.7.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.7.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.7.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.8.norm1.weight\n",
      "blip.visual_encoder.blocks.8.norm1.bias\n",
      "blip.visual_encoder.blocks.8.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.8.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.8.attn.proj.weight\n",
      "blip.visual_encoder.blocks.8.attn.proj.bias\n",
      "blip.visual_encoder.blocks.8.norm2.weight\n",
      "blip.visual_encoder.blocks.8.norm2.bias\n",
      "blip.visual_encoder.blocks.8.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.8.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.8.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.8.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.9.norm1.weight\n",
      "blip.visual_encoder.blocks.9.norm1.bias\n",
      "blip.visual_encoder.blocks.9.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.9.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.9.attn.proj.weight\n",
      "blip.visual_encoder.blocks.9.attn.proj.bias\n",
      "blip.visual_encoder.blocks.9.norm2.weight\n",
      "blip.visual_encoder.blocks.9.norm2.bias\n",
      "blip.visual_encoder.blocks.9.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.9.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.9.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.9.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.10.norm1.weight\n",
      "blip.visual_encoder.blocks.10.norm1.bias\n",
      "blip.visual_encoder.blocks.10.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.10.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.10.attn.proj.weight\n",
      "blip.visual_encoder.blocks.10.attn.proj.bias\n",
      "blip.visual_encoder.blocks.10.norm2.weight\n",
      "blip.visual_encoder.blocks.10.norm2.bias\n",
      "blip.visual_encoder.blocks.10.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.10.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.10.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.10.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.11.norm1.weight\n",
      "blip.visual_encoder.blocks.11.norm1.bias\n",
      "blip.visual_encoder.blocks.11.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.11.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.11.attn.proj.weight\n",
      "blip.visual_encoder.blocks.11.attn.proj.bias\n",
      "blip.visual_encoder.blocks.11.norm2.weight\n",
      "blip.visual_encoder.blocks.11.norm2.bias\n",
      "blip.visual_encoder.blocks.11.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.11.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.11.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.11.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.12.norm1.weight\n",
      "blip.visual_encoder.blocks.12.norm1.bias\n",
      "blip.visual_encoder.blocks.12.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.12.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.12.attn.proj.weight\n",
      "blip.visual_encoder.blocks.12.attn.proj.bias\n",
      "blip.visual_encoder.blocks.12.norm2.weight\n",
      "blip.visual_encoder.blocks.12.norm2.bias\n",
      "blip.visual_encoder.blocks.12.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.12.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.12.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.12.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.13.norm1.weight\n",
      "blip.visual_encoder.blocks.13.norm1.bias\n",
      "blip.visual_encoder.blocks.13.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.13.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.13.attn.proj.weight\n",
      "blip.visual_encoder.blocks.13.attn.proj.bias\n",
      "blip.visual_encoder.blocks.13.norm2.weight\n",
      "blip.visual_encoder.blocks.13.norm2.bias\n",
      "blip.visual_encoder.blocks.13.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.13.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.13.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.13.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.14.norm1.weight\n",
      "blip.visual_encoder.blocks.14.norm1.bias\n",
      "blip.visual_encoder.blocks.14.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.14.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.14.attn.proj.weight\n",
      "blip.visual_encoder.blocks.14.attn.proj.bias\n",
      "blip.visual_encoder.blocks.14.norm2.weight\n",
      "blip.visual_encoder.blocks.14.norm2.bias\n",
      "blip.visual_encoder.blocks.14.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.14.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.14.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.14.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.15.norm1.weight\n",
      "blip.visual_encoder.blocks.15.norm1.bias\n",
      "blip.visual_encoder.blocks.15.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.15.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.15.attn.proj.weight\n",
      "blip.visual_encoder.blocks.15.attn.proj.bias\n",
      "blip.visual_encoder.blocks.15.norm2.weight\n",
      "blip.visual_encoder.blocks.15.norm2.bias\n",
      "blip.visual_encoder.blocks.15.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.15.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.15.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.15.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.16.norm1.weight\n",
      "blip.visual_encoder.blocks.16.norm1.bias\n",
      "blip.visual_encoder.blocks.16.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.16.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.16.attn.proj.weight\n",
      "blip.visual_encoder.blocks.16.attn.proj.bias\n",
      "blip.visual_encoder.blocks.16.norm2.weight\n",
      "blip.visual_encoder.blocks.16.norm2.bias\n",
      "blip.visual_encoder.blocks.16.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.16.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.16.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.16.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.17.norm1.weight\n",
      "blip.visual_encoder.blocks.17.norm1.bias\n",
      "blip.visual_encoder.blocks.17.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.17.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.17.attn.proj.weight\n",
      "blip.visual_encoder.blocks.17.attn.proj.bias\n",
      "blip.visual_encoder.blocks.17.norm2.weight\n",
      "blip.visual_encoder.blocks.17.norm2.bias\n",
      "blip.visual_encoder.blocks.17.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.17.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.17.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.17.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.18.norm1.weight\n",
      "blip.visual_encoder.blocks.18.norm1.bias\n",
      "blip.visual_encoder.blocks.18.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.18.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.18.attn.proj.weight\n",
      "blip.visual_encoder.blocks.18.attn.proj.bias\n",
      "blip.visual_encoder.blocks.18.norm2.weight\n",
      "blip.visual_encoder.blocks.18.norm2.bias\n",
      "blip.visual_encoder.blocks.18.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.18.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.18.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.18.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.19.norm1.weight\n",
      "blip.visual_encoder.blocks.19.norm1.bias\n",
      "blip.visual_encoder.blocks.19.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.19.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.19.attn.proj.weight\n",
      "blip.visual_encoder.blocks.19.attn.proj.bias\n",
      "blip.visual_encoder.blocks.19.norm2.weight\n",
      "blip.visual_encoder.blocks.19.norm2.bias\n",
      "blip.visual_encoder.blocks.19.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.19.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.19.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.19.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.20.norm1.weight\n",
      "blip.visual_encoder.blocks.20.norm1.bias\n",
      "blip.visual_encoder.blocks.20.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.20.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.20.attn.proj.weight\n",
      "blip.visual_encoder.blocks.20.attn.proj.bias\n",
      "blip.visual_encoder.blocks.20.norm2.weight\n",
      "blip.visual_encoder.blocks.20.norm2.bias\n",
      "blip.visual_encoder.blocks.20.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.20.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.20.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.20.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.21.norm1.weight\n",
      "blip.visual_encoder.blocks.21.norm1.bias\n",
      "blip.visual_encoder.blocks.21.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.21.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.21.attn.proj.weight\n",
      "blip.visual_encoder.blocks.21.attn.proj.bias\n",
      "blip.visual_encoder.blocks.21.norm2.weight\n",
      "blip.visual_encoder.blocks.21.norm2.bias\n",
      "blip.visual_encoder.blocks.21.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.21.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.21.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.21.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.22.norm1.weight\n",
      "blip.visual_encoder.blocks.22.norm1.bias\n",
      "blip.visual_encoder.blocks.22.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.22.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.22.attn.proj.weight\n",
      "blip.visual_encoder.blocks.22.attn.proj.bias\n",
      "blip.visual_encoder.blocks.22.norm2.weight\n",
      "blip.visual_encoder.blocks.22.norm2.bias\n",
      "blip.visual_encoder.blocks.22.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.22.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.22.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.22.mlp.fc2.bias\n",
      "blip.visual_encoder.blocks.23.norm1.weight\n",
      "blip.visual_encoder.blocks.23.norm1.bias\n",
      "blip.visual_encoder.blocks.23.attn.qkv.weight\n",
      "blip.visual_encoder.blocks.23.attn.qkv.bias\n",
      "blip.visual_encoder.blocks.23.attn.proj.weight\n",
      "blip.visual_encoder.blocks.23.attn.proj.bias\n",
      "blip.visual_encoder.blocks.23.norm2.weight\n",
      "blip.visual_encoder.blocks.23.norm2.bias\n",
      "blip.visual_encoder.blocks.23.mlp.fc1.weight\n",
      "blip.visual_encoder.blocks.23.mlp.fc1.bias\n",
      "blip.visual_encoder.blocks.23.mlp.fc2.weight\n",
      "blip.visual_encoder.blocks.23.mlp.fc2.bias\n",
      "blip.visual_encoder.norm.weight\n",
      "blip.visual_encoder.norm.bias\n",
      "blip.text_encoder.embeddings.position_ids\n",
      "blip.text_encoder.embeddings.word_embeddings.weight\n",
      "blip.text_encoder.embeddings.position_embeddings.weight\n",
      "blip.text_encoder.embeddings.LayerNorm.weight\n",
      "blip.text_encoder.embeddings.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.0.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.0.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.0.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.0.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.0.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.0.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.0.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.0.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.0.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.0.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.0.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.0.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.0.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.0.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.0.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.0.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.0.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.0.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.0.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.0.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.0.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.0.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.0.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.0.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.1.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.1.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.1.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.1.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.1.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.1.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.1.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.1.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.1.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.1.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.1.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.1.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.1.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.1.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.1.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.1.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.1.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.1.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.1.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.1.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.1.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.1.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.1.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.1.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.2.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.2.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.2.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.2.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.2.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.2.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.2.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.2.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.2.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.2.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.2.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.2.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.2.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.2.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.2.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.2.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.2.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.2.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.2.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.2.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.2.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.2.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.2.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.2.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.3.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.3.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.3.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.3.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.3.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.3.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.3.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.3.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.3.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.3.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.3.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.3.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.3.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.3.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.3.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.3.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.3.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.3.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.3.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.3.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.3.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.3.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.3.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.3.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.4.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.4.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.4.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.4.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.4.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.4.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.4.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.4.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.4.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.4.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.4.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.4.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.4.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.4.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.4.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.4.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.4.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.4.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.4.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.4.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.4.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.4.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.4.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.4.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.5.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.5.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.5.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.5.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.5.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.5.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.5.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.5.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.5.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.5.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.5.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.5.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.5.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.5.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.5.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.5.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.5.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.5.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.5.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.5.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.5.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.5.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.5.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.5.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.6.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.6.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.6.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.6.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.6.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.6.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.6.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.6.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.6.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.6.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.6.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.6.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.6.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.6.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.6.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.6.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.6.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.6.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.6.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.6.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.6.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.6.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.6.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.6.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.7.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.7.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.7.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.7.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.7.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.7.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.7.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.7.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.7.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.7.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.7.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.7.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.7.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.7.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.7.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.7.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.7.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.7.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.7.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.7.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.7.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.7.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.7.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.7.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.8.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.8.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.8.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.8.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.8.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.8.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.8.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.8.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.8.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.8.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.8.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.8.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.8.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.8.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.8.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.8.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.8.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.8.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.8.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.8.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.8.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.8.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.8.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.8.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.9.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.9.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.9.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.9.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.9.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.9.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.9.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.9.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.9.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.9.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.9.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.9.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.9.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.9.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.9.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.9.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.9.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.9.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.9.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.9.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.9.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.9.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.10.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.10.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.10.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.10.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.10.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.10.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.10.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.10.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.10.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.10.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.10.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.10.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.10.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.10.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.10.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.10.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.10.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.10.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.10.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.10.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.10.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.10.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.11.attention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.11.attention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.11.attention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.11.attention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.11.attention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.11.attention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.11.attention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.11.attention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.11.crossattention.self.query.weight\n",
      "blip.text_encoder.encoder.layer.11.crossattention.self.query.bias\n",
      "blip.text_encoder.encoder.layer.11.crossattention.self.key.weight\n",
      "blip.text_encoder.encoder.layer.11.crossattention.self.key.bias\n",
      "blip.text_encoder.encoder.layer.11.crossattention.self.value.weight\n",
      "blip.text_encoder.encoder.layer.11.crossattention.self.value.bias\n",
      "blip.text_encoder.encoder.layer.11.crossattention.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.11.crossattention.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias\n",
      "blip.text_encoder.encoder.layer.11.intermediate.dense.weight\n",
      "blip.text_encoder.encoder.layer.11.intermediate.dense.bias\n",
      "blip.text_encoder.encoder.layer.11.output.dense.weight\n",
      "blip.text_encoder.encoder.layer.11.output.dense.bias\n",
      "blip.text_encoder.encoder.layer.11.output.LayerNorm.weight\n",
      "blip.text_encoder.encoder.layer.11.output.LayerNorm.bias\n",
      "blip.vision_proj.weight\n",
      "blip.vision_proj.bias\n",
      "blip.text_proj.weight\n",
      "blip.text_proj.bias\n",
      "mlp.layers.0.weight\n",
      "mlp.layers.0.bias\n",
      "mlp.layers.2.weight\n",
      "mlp.layers.2.bias\n",
      "mlp.layers.4.weight\n",
      "mlp.layers.4.bias\n",
      "mlp.layers.6.weight\n",
      "mlp.layers.6.bias\n",
      "mlp.layers.7.weight\n",
      "mlp.layers.7.bias\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "state_dict = torch.load(\"/root/autodl-tmp/VQualA/alignment_module/imagereward.pth\")\n",
    "\n",
    "for key, value in state_dict.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fed487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VQualA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
